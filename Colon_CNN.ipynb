{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0ee547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcd1863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dl\\AppData\\Local\\Temp\\ipykernel_7096\\337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5650d495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5c348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10102e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['good','bad']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "def load_data():\n",
    "    datasets = ['train', 'test']#資料夾\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                #cv讀照片，顏色莫認為BGR，需轉為RGB，錯誤表示黑白或已轉\n",
    "                image = cv2.resize(image, IMAGE_SIZE)  \n",
    "                #image = Image.convert(\"L\")\n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')   \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f7dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨機性\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)\n",
    "#標準化\n",
    "train_images = train_images / 255.0 \n",
    "test_images = test_images / 255.0\n",
    "#建模\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), input_shape=input_shape, padding='same',activation='relu', strides=2),\n",
    "    Conv2D(64, (3, 3), input_shape=input_shape, padding='same',activation='relu', strides=2),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(128, (3, 3), input_shape=input_shape, padding='same',activation='relu', strides=2),\n",
    "    Conv2D(128, (3, 3), input_shape=input_shape, padding='same',activation='relu', strides=2),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(256, (3, 3), input_shape=input_shape, padding='same',activation='relu', strides=2),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Flatten(),#平坦層\n",
    "    \n",
    "    Dense(units=512, activation='relu'),#隱藏層1\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(units=512, activation='relu'),#隱藏層2\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(2, activation='softmax') #輸出層，分類用softmax，只分好壞是2\n",
    "])\n",
    "model.compile(optimizer = 'adam', #SGD(lr=0.1)\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfe34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_images,y=train_labels,epochs=30,batch_size=200,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ca97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型概況\n",
    "plt.title('train_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(history.history[\"loss\"])\n",
    "#scores = model.evaluate(test_images,test_labels)\n",
    "#print('test:',result[1])\n",
    "#預測\n",
    "predictions = model.predict(test_images)#Vector of probabilities\n",
    "pred_labels = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12c187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8486111111111111\n"
     ]
    }
   ],
   "source": [
    "CM = confusion_matrix(test_labels,pred_labels)\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements =confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "print(accuracy(CM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70757957",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00082e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#混淆矩陣視覺化,看錯誤\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True,\n",
    "            annot_kws={\"size\": 10},\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names, ax = ax)\n",
    "ax.set_title ('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646f45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#存模型&讀模型\n",
    "model.save(\"ColonModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a66fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('ColonModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bda198",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_path=r'C:\\Users\\dl\\Desktop\\yc_data\\colon_AI\\test\\good\\good11_35.jpg'\n",
    "img=tf.keras.preprocessing.image.load_img(IMAGE_path,target_size=(224,224))\n",
    "img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "#img=tf.image.rgb_to_grayscale(img) \n",
    "plt.imshow(img/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a3def5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n",
      "bad\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(np.array([img]),verbose=0)\n",
    "print(prediction)\n",
    "if prediction[0,0]>prediction[0,1]:\n",
    "    print(\"good\")\n",
    "else:\n",
    "    print(\"bad\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6644d9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011339865"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ca161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
